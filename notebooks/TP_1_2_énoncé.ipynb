{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mart1Portfolio/ensai-apprentissage-profond/blob/main/notebooks/TP_1_2_%C3%A9nonc%C3%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmIXu4LsvsCY"
      },
      "source": [
        "**Avant de débuter ce TP** :\n",
        "\n",
        "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
        "2. **Installez les paquets ci-dessous** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t98aoXcSvsCb",
        "outputId": "b4a0107e-51cf-4ba7-8088-e976bc073d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightning in /usr/local/lib/python3.12/dist-packages (2.5.5)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (0.15.2)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (25.0)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.15.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning) (2.5.5)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.10)\n"
          ]
        }
      ],
      "source": [
        "! pip install lightning torchmetrics torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zShI625GvsCd"
      },
      "source": [
        "3. Exécutez ce code pour supprimer quelques messages et avertissements éventuellement affichés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "DEOSrHR8vsCe"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
        "logger = logging.getLogger(\"lightning\")\n",
        "logger.propagate = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
        "warnings.filterwarnings(\"ignore\", \".*Missing logger folder.*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBGDvNGmvsCe"
      },
      "source": [
        "# Mon premier réseau de neurones artificiels\n",
        "\n",
        "Durant la deuxième partie de ce premier TP, vous allez travailler sur un autre jeu de données : [*forest cover types*](https://archive.ics.uci.edu/dataset/31/covertype).\n",
        "L'objectif est de prédire le type d'un arbre de forêt à partir de certaines caractéristiques.\n",
        "Il s'agit d'un problème de **classification**.\n",
        "\n",
        "En utilisant ce que vous avez appris dans le TP précédent, vous allez devoir :\n",
        "\n",
        "* **prétraiter les données**,\n",
        "* **indiquer comment accéder aux données**,\n",
        "* **construire un réseau de neurones**,\n",
        "* **entraîner et évaluer ce réseau de neurones**\n",
        "\n",
        "Nous utiliserons le paquet `scikit-learn` pour télécharger ce jeu de données. Comme d'habitude, on installe les paquets nécessaires qui ne sont pas déjà installés sur Colab :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsMbxZLpvsCf"
      },
      "source": [
        "Nous allons (télé)charger ce jeu de données en utilisant la fonction [`sklearn.datasets.fetch_covtype()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html).\n",
        "En résumé, cette fonction renvoie deux variables :\n",
        "\n",
        "* `X` est une matrice (un tableau NumPy à deux dimensions) de taille $n \\times p$ où $n$ est le nombre d'observations et $p$ est le nombre de variables. Ce sont les données en entrée.\n",
        "* `y` est un vecteur (un tableau NumPy à une dimension) de taille $n$. Ce sont les données en sortie (à prédire)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "1qfDZ263vsCg"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "X, y = fetch_covtype(data_home='data', return_X_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur9naYz2vsCh"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "1. Déterminez la taille du jeu de données, c'est-à-dire le nombre d'observations $n$ et le nombre de variables $p$. Vous pouvez utiliser l'attribut [`numpy.ndarray.shape`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.shape.html)\n",
        "\n",
        "2. Déterminez le nombre de classes. Est-ce que les classes sont équilibrées ? Vous pouvez utiliser la fonction [`numpy.unique()`](https://numpy.org/doc/stable/reference/generated/numpy.unique.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "Bix9SwLovsCi",
        "outputId": "b5a0a8d4-4164-4412-d171-139ba061361a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(581012, 54) (581012,)\n",
            "Nombre de classes : 7\n",
            "Classes équilibrées : [211840 283301  35754   2747   9493  17367  20510]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 7 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO\n",
        "import numpy as np\n",
        "print(X.shape, y.shape)\n",
        "print(f\"Nombre de classes : {len(np.unique(y))}\")\n",
        "print(f\"Classes équilibrées : {np.unique(y, return_counts=True)[1]}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "plt.bar(np.unique(y), np.unique(y, return_counts=True)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notre jeu de données est composé de 581 012 observations composées de 54 variables plus la variable à prédire.\n",
        "On constate que les classes sont peu équilibrées car certains types d'arbres sont bcp + présents."
      ],
      "metadata": {
        "id": "6geZJC0H2Gcz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wn-zYMQvsCi"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Séparez le jeu de données en trois :\n",
        "* un jeu d'entraînement avec 100 000 observations,\n",
        "* un jeu de validation avec 100 000 observations,\n",
        "* un jeu d'évaluation (reste).\n",
        "\n",
        "Vous pouvez utiliser la fonction [`sklearn.model_selection.train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
        "Assurez-vous que la distribution des classes est identique dans les trois sous-jeux de données en utilisant le paramètre `stratify`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "jIIuHzLmvsCj"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_remaining, y_train, y_remaining = train_test_split(X, y, train_size= 100000, stratify = y)\n",
        "x_test, x_eval, y_test, y_eval = train_test_split(x_remaining, y_remaining, train_size= 100000, stratify = y_remaining)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yne1i8vvsCj"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Convertissez les tableaux NumPy en tenseurs PyTorch. N'oubliez pas de changer le type des données :\n",
        "* les données en entrée (`X`) doivent passer de `numpy.float64` à `torch.float32`,\n",
        "* les données en sortie (`y`) doivent passer de `numpy.int32` à `torch.int64`.\n",
        "\n",
        "Vous pouvez utiliser la fonction [`torch.from_numpy()`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) et la méthode [`torch.Tensor.to()`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html).\n",
        "\n",
        "> **Remarque** : Pour les tâches de classification, il est nécessaire de fournir une représentation adaptée des classes pour la fonction de coût. La représentation la plus simple pour une tâche de classification multi-classes est d'utiliser les $K$ premiers entiers naturels (en commençant à partir de zéro), c'est-à-dire les entiers $0, \\ldots, K-1$, $K$ étant le nombre de classes. De cette manière, la correspondance entre la dernière couche du réseau de neurones (renvoyant les probabilités ou les logits) et les classes est basée sur les indicies : `probabilité[k]` correspond à la probabilité d'appartenir à la classe $k$ pour chaque $k \\in \\{ 0, \\ldots, K-1 \\}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "FvkPd3rqvsCj"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "import torch\n",
        "y = y-1\n",
        "x_train = torch.from_numpy(x_train).to(torch.float32)\n",
        "x_test = torch.from_numpy(x_test).to(torch.float32)\n",
        "x_eval = torch.from_numpy(x_eval).to(torch.float32)\n",
        "\n",
        "y_train = torch.from_numpy(y_train).to(torch.float64)\n",
        "y_test = torch.from_numpy(y_test).to(torch.float64)\n",
        "y_eval = torch.from_numpy(y_eval).to(torch.float64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbWeRonjvsCk"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "Créez des instances de la classe [`torch.utils.data.Dataloader()`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) pour chacun des jeux (entraînement, validation et évaluation). Pour les jeux de données, vous pouvez utiliser la classe [`torch.utils.data.TensorDataset()`](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "bPOjmV0ovsCk"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "from torch.utils.data import TensorDataset\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "test_dataset = TensorDataset(x_test, y_test)\n",
        "eval_dataset = TensorDataset(x_eval, y_eval)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True, )\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size = 32, shuffle = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx5SYdcYvsCk"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "La définition des caractéristiques principales du modèle (architecture) et de son entraînement (algorithme d'optimisation, fonction de perte, métrique d'évaluation) se fait dans une même classe.\n",
        "Complétez les méthodes `__init__()`, `forward()` et `configure_optimizers()` de la classe `NeuralNetwork` définie ci-dessous en utilisant les informations fournies dans le texte ci-dessous.\n",
        "\n",
        "#### Architecture\n",
        "\n",
        "L'architecture de votre réseau de neurones est un **perceptron multicouche** avec les caractéristiques suivantes :\n",
        "* *Première couche cachée* : couche linéaire (128 variables en sortie) + fonction d'activation ReLU\n",
        "* *Deuxième couche cachée* : couche linéaire (64 variables en sortie) + fonction d'activation ReLU\n",
        "* *Dernière couche cachée* : couche linéaire (à vous de déterminer la taille de la sortie)\n",
        "\n",
        "Pour rappel, les couches sont initialisées dans le constructeur et la définition de la passe avant se fait dans la méthode `forward()`.\n",
        "Vous êtes encouragés à aller lire la documentation de [`torch.nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html), [`torch.nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) et [`torch.nn.Sequential()`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html).\n",
        "\n",
        "#### Entraînement\n",
        "\n",
        "Le modèle sera entraîné en utilisant l'entropie croisée comme fonction de perte et Adam avec les valeurs par défaut pour ses hyperparamètres comme algorithme d'optimisation.\n",
        "Vous êtes encouragés à aller lire la documentation de [`torch.nn.CrossEntropyLoss()`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) et [`torch.optim.Adam()`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html).\n",
        "\n",
        "#### Métrique\n",
        "\n",
        "La performance d'un modèle sera évalué en utilisant l'exactitude (*accuracy*).\n",
        "Vous pouvez utiliser [`torchmetrics.Accuracy()`](https://lightning.ai/docs/torchmetrics/stable/classification/accuracy.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "PXlwSCp5vsCl"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "\n",
        "class NeuralNetwork(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructeur.\n",
        "\n",
        "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
        "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
        "        \"\"\"\n",
        "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "        # Initialisation de la séquence de couches et de fonctions d'activation\n",
        "        self.sequential = torch.nn.Sequential(\n",
        "            torch.nn.Linear(1*54, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(64,7)\n",
        "        )\n",
        "        # Initialisation de la fonction de perte\n",
        "        self.loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        # Initialisation des métriques d'évaluation\n",
        "        self.accuracy_train = Accuracy(task=\"multiclass\", num_classes=7)\n",
        "        self.accuracy_val = Accuracy(task=\"multiclass\", num_classes=7)\n",
        "        self.accuracy_test = Accuracy(task=\"multiclass\", num_classes=7)\n",
        "        #### END TODO ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implémente la passe avant.\n",
        "\n",
        "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
        "        observation soit aux entrées d'un lot d'observations.\n",
        "        \"\"\"\n",
        "        ### BEGIN TODO ###\n",
        "        y = self.sequential(x)\n",
        "        #### END TODO ####\n",
        "        return y\n",
        "\n",
        "    def step(self, batch, dataset):\n",
        "        \"\"\"Effectue une étape.\n",
        "\n",
        "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
        "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch : tuple\n",
        "            Un lot d'observations. Le premier élément du tuple est le lot\n",
        "            des entrées, le second est le lot des labels.\n",
        "\n",
        "        dataset : {\"training\", \"validation\", \"test\"}\n",
        "            Jeu de données utilisé.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : Tensor, shape = (1,)\n",
        "            La fonction de coût pour ce lot d'observations.\n",
        "        \"\"\"\n",
        "        X, y = batch  # X correspond aux images, y aux classes\n",
        "        logits = self(X)  # Passe avant, qui renvoie les logits\n",
        "        loss = self.loss(logits, y)  # Évaluation de la fonction de perte\n",
        "        y_pred = logits.argmax(1)  # Prédictions du modèle\n",
        "\n",
        "        if dataset == \"training\":\n",
        "            metric = self.accuracy_train\n",
        "            name = \"train\"\n",
        "            bar_step = True\n",
        "        elif dataset == \"validation\":\n",
        "            metric = self.accuracy_val\n",
        "            name = \"val\"\n",
        "            bar_step = False\n",
        "        else:\n",
        "            metric = self.accuracy_test\n",
        "            name = \"test\"\n",
        "            bar_step = False\n",
        "\n",
        "        acc = metric(y_pred, y) # Évaluation de la métrique\n",
        "        self.log(f\"loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "        self.log(f\"accuracy_{name}\", acc, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
        "        return self.step(batch, \"training\")\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        \"\"\"Effectue une étape de validation.\"\"\"\n",
        "        return self.step(batch, \"validation\")\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
        "        return self.step(batch, \"test\")\n",
        "\n",
        "    def on_train_start(self):\n",
        "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
        "        string = f\"Version {self.trainer.logger.version}\"\n",
        "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
        "        metrics = self.trainer.callback_metrics\n",
        "        string = (f\"\"\"\n",
        "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
        "            -------------------------------------------------\n",
        "            |     Jeu      | Fonction de perte | Exactitude |\n",
        "            | ------------ | ----------------- | ---------- |\n",
        "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['accuracy_train'].item():^12.3%}|\n",
        "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['accuracy_val'].item():^12.3%}|\n",
        "            -------------------------------------------------\n",
        "        \"\"\")\n",
        "        string = '\\n'.join([line.strip() for line in string.strip().split('\\n')])\n",
        "        print(string, \"\\n\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
        "        ### BEGIN TODO ###\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        #### END TODO ####\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYgKSE88vsCm"
      },
      "source": [
        "On va maintenant entraîner le modèle pendant 10 époques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495,
          "referenced_widgets": [
            "0a3ed71beea443ff9acdff2ff5a06af3",
            "1d28d5d572da4ff8a99f94b7a2cdb574",
            "eb9beb46af1e4c95a814061f792ca87c",
            "94576980db484b72b746dd6d7e83f416",
            "3f17413dc89142e5b9902c1edc6a4d61",
            "a390b81387b8402b958fdc9f3a089bef",
            "1f43b61358a4467ca866fc3aea8abd90",
            "6f345c4494d841afbe98446de965d25a",
            "086febc366184ee186605bab47655466",
            "f84d8955acde4f3abef3a21f6d8d6ca2",
            "5fd22ba54de44cd082eba82376c6d569"
          ]
        },
        "id": "CHXB5stevsCm",
        "outputId": "5301cac4-2538-4013-b9a7-7a5388ca90b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:484: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a3ed71beea443ff9acdff2ff5a06af3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version 2\n",
            "=========\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Double'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1980274722.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m trainer.fit(\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         )\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected state {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                     \u001b[0;31m# in automatic optimization, there can only be one optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# gradient update with accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         call._call_lightning_module_hook(\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;34m\"optimizer_step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \"\"\"\n\u001b[0;32m-> 1366\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model_and_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/plugins/precision/precision.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;34m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     def _clip_gradients(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                             )\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/plugins/precision/precision.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# unused hook - call anyway for backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_redirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2702837766.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;34m\"\"\"Effectue une étape d'entraînement.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2702837766.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, batch, dataset)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m  \u001b[0;31m# X correspond aux images, y aux classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Passe avant, qui renvoie les logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Évaluation de la fonction de perte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Prédictions du modèle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1311\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3461\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3462\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3463\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Double'"
          ]
        }
      ],
      "source": [
        "from lightning.pytorch.callbacks import TQDMProgressBar\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=10,\n",
        "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
        "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
        "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
        "    callbacks=[TQDMProgressBar(refresh_rate=100)]  # mettre à jour la barre de progression tous les 100 lots\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=model,\n",
        "    train_dataloaders=train_dataloader,\n",
        "    val_dataloaders=eval_dataloader\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRHrrKe0vsCm"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "Est-ce que l'exactitude (*accuracy*) est une métrique appropriée ici ?\n",
        "Quelle métrique serait davantage pertinente ?\n",
        "Y a-t-il également des modifications à faire pour potentiellement améliorer l'entraînement ?\n",
        "Regardez la documentation de [`torchmetrics.Accuracy()`](https://lightning.ai/docs/torchmetrics/stable/classification/accuracy.html) et de [`torch.nn.CrossEntropyLoss()`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) et faîtes les modifications nécessaires dans la méthode `forward()`.\n",
        "Vous pouvez utiliser la fonction [`torch.bincount()`](https://pytorch.org/docs/stable/generated/torch.bincount.html) pour compter le nombre d'observations pour les différentes classes.\n",
        "\n",
        "> **Remarque** : L'exactitude équilibrée (*balanced accuracy*) nécessite de connaître la distribution des classes pour connaître les poids des classes. La distribution des classes étant connue à la fin (quand on a parcouru tout le jeu de données), il n'est donc pas possible de calculer les scores d'exactitude équilibrée sur tous les lots intermédiaires. La bonne approche est de *mettre à jour* la métrique (avec la méthode `update()`) à chaque étape (*step*), puis de calculer l'exactitude équilibrée à la fin de l'époque (avec la méthode `compute()`) et enfin de réinitialiser les informations sauvegardées sous le capot pour calculer l'exactitude équilibrée (avec la méthode `reset()`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_bX4GG3vsCm"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "from torch import nn\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "\n",
        "class NeuralNetworkUpdated(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructeur.\n",
        "\n",
        "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
        "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
        "        \"\"\"\n",
        "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
        "\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(54, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 7),\n",
        "        )\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "        # self.loss =\n",
        "        # self.bal_acc_train =\n",
        "        # self.bal_acc_val =\n",
        "        # self.bal_acc_test =\n",
        "        #### END TODO ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implémente la passe avant.\n",
        "\n",
        "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
        "        observation soit aux entrées d'un lot d'observations.\n",
        "        \"\"\"\n",
        "        return self.sequential(x)\n",
        "\n",
        "    def step(self, batch, dataset):\n",
        "        \"\"\"Effectue une étape.\n",
        "\n",
        "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
        "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch : tuple\n",
        "            Un lot d'observations. Le premier élément du tuple est le lot\n",
        "            des entrées, le second est le lot des labels.\n",
        "\n",
        "        dataset : {\"training\", \"validation\", \"test\"}\n",
        "            Jeu de données utilisé.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : Tensor, shape = (1,)\n",
        "            La fonction de coût pour ce lot d'observations.\n",
        "        \"\"\"\n",
        "        X, y = batch  # X correspond aux images, y aux classes\n",
        "        logits = self(X)  # Passe avant, qui renvoie les logits\n",
        "        loss = self.loss(logits, y)  # Évaluation de la fonction de perte\n",
        "        y_pred = logits.argmax(1)  # Prédictions du modèle\n",
        "\n",
        "        if dataset == \"training\":\n",
        "            metric = self.bal_acc_train\n",
        "            name = \"train\"\n",
        "            bar_step = True\n",
        "        elif dataset == \"validation\":\n",
        "            metric = self.bal_acc_val\n",
        "            name = \"val\"\n",
        "            bar_step = False\n",
        "        else:\n",
        "            metric = self.bal_acc_test\n",
        "            name = \"test\"\n",
        "            bar_step = False\n",
        "\n",
        "        acc = metric(y_pred, y) # Évaluation de la métrique\n",
        "        self.log(f\"weighted_loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "        self.log(f\"balanced_accuracy_{name}\", acc, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
        "        return self.step(batch, \"training\")\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        \"\"\"Effectue une étape de validation.\"\"\"\n",
        "        return self.step(batch, \"validation\")\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
        "        return self.step(batch, \"test\")\n",
        "\n",
        "    def on_train_start(self):\n",
        "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
        "        string = f\"Version {self.trainer.logger.version}\"\n",
        "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
        "        self.log('balanced_accuracy_train', self.bal_acc_train.compute())\n",
        "        self.bal_acc_train.reset()\n",
        "\n",
        "        metrics = self.trainer.callback_metrics\n",
        "        weighted_loss_train = metrics['weighted_loss_train'].item()\n",
        "        weighted_loss_val = metrics['weighted_loss_val'].item()\n",
        "        bal_acc_train = metrics['balanced_accuracy_train'].item()\n",
        "        bal_acc_val = metrics['balanced_accuracy_val'].item()\n",
        "\n",
        "        string = (f\"\"\"\n",
        "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
        "            ------------------------------------------------------------\n",
        "            |     Jeu      | Fonction de perte | Exactitude équilibrée |\n",
        "            | ------------ | ----------------- | --------------------- |\n",
        "            | Entraînement |{weighted_loss_train:^19.5f}|{bal_acc_train:^23.3%}|\n",
        "            |  Validation  |{weighted_loss_val:^19.5f}|{bal_acc_val:^23.3%}|\n",
        "            ------------------------------------------------------------\n",
        "        \"\"\")\n",
        "        string = '\\n'.join([line.strip() for line in string.strip().split('\\n')])\n",
        "        print(string, \"\\n\")\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.log('bal_acc_val', self.bal_acc_val.compute())\n",
        "        self.bal_acc_val.reset()\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.log('bal_acc_test', self.bal_acc_test.compute())\n",
        "        self.bal_acc_test.reset()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym-cOgl2vsCn"
      },
      "source": [
        "On entraîne un nouveau modèle pendant $10$ époques également."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c83Tun6BvsCn"
      },
      "outputs": [],
      "source": [
        "model_updated = NeuralNetworkUpdated()\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=10,\n",
        "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
        "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
        "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
        "    callbacks=[TQDMProgressBar(refresh_rate=100)]  # mettre à jour la barre de progression tous les 100 lots\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=model_updated,\n",
        "    train_dataloaders=dataloader_train,\n",
        "    val_dataloaders=dataloader_val\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx9dQq4-vsCo"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "Faîtes les modifications que vous souhaitez, par exemple au niveau de l'architecture ou de la procédure d'entraînement, et entraînez vos nouveaux modèles.\n",
        "**Gardez vos modèles précédents** et créez de nouveaux objets à chaque fois, afin de pouvoir comparer ces différents modèles ensuite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3zeRsBdvsCo"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d23FXb9vsCo"
      },
      "source": [
        "### Question 8\n",
        "\n",
        "Quand vous avez fini toutes vos expériences, il est temps de choisir le meilleur modèle sur le jeu de validation.\n",
        "Évaluez sa performance sur le jeu d'évaluation.\n",
        "Par curiosité, évaluez également la performance des autres modèles sur le jeu d'évaluation.\n",
        "Vous êtes encouragés à aller lire la [documentation](https://lightning.ai/docs/torchmetrics/stable/pages/overview.html) de `torchmetrics` pour découvrir le principe d'utilisation des métriques implémentées dans ce paquet.\n",
        "\n",
        "> **Remarque** : La première classe utilise l'exactitude (*accuracy*) comme métrique d'évaluation, tandis que la deuxième classe utilise l'exactitude équilibrée (*balanced accuracy*). Il n'est évidemment pas pertinent de comparer des scores d'exactitude avec des scores d'exactitude équilibrée. De même, la fonction de perte est maintenant pondérée dans la deuxième classe. Il n'est donc pas possible d'utiliser les méthodes `validate()` et `test()` pour comparer des modèles définis par des classes différentes si les classes utilisent différents critères d'évaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Szi2sAeEvsCo"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a3ed71beea443ff9acdff2ff5a06af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d28d5d572da4ff8a99f94b7a2cdb574",
              "IPY_MODEL_eb9beb46af1e4c95a814061f792ca87c",
              "IPY_MODEL_94576980db484b72b746dd6d7e83f416"
            ],
            "layout": "IPY_MODEL_3f17413dc89142e5b9902c1edc6a4d61"
          }
        },
        "1d28d5d572da4ff8a99f94b7a2cdb574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a390b81387b8402b958fdc9f3a089bef",
            "placeholder": "​",
            "style": "IPY_MODEL_1f43b61358a4467ca866fc3aea8abd90",
            "value": "Epoch 0:   0%"
          }
        },
        "eb9beb46af1e4c95a814061f792ca87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f345c4494d841afbe98446de965d25a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_086febc366184ee186605bab47655466",
            "value": 0
          }
        },
        "94576980db484b72b746dd6d7e83f416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84d8955acde4f3abef3a21f6d8d6ca2",
            "placeholder": "​",
            "style": "IPY_MODEL_5fd22ba54de44cd082eba82376c6d569",
            "value": " 0/3125 [00:00&lt;?, ?it/s]"
          }
        },
        "3f17413dc89142e5b9902c1edc6a4d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a390b81387b8402b958fdc9f3a089bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f43b61358a4467ca866fc3aea8abd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f345c4494d841afbe98446de965d25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "086febc366184ee186605bab47655466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f84d8955acde4f3abef3a21f6d8d6ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fd22ba54de44cd082eba82376c6d569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}