{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mart1Portfolio/ensai-apprentissage-profond/blob/main/notebooks/TP_1_2_%C3%A9nonc%C3%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmIXu4LsvsCY"
      },
      "source": [
        "**Avant de débuter ce TP** :\n",
        "\n",
        "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
        "2. **Installez les paquets ci-dessous** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t98aoXcSvsCb",
        "outputId": "28cbed92-84f7-460c-8cf4-721d8b21729a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightning in /usr/local/lib/python3.12/dist-packages (2.5.5)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (0.15.2)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (25.0)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.15.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning) (2.5.5)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.10)\n"
          ]
        }
      ],
      "source": [
        "! pip install lightning torchmetrics torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zShI625GvsCd"
      },
      "source": [
        "3. Exécutez ce code pour supprimer quelques messages et avertissements éventuellement affichés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DEOSrHR8vsCe"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
        "logger = logging.getLogger(\"lightning\")\n",
        "logger.propagate = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
        "warnings.filterwarnings(\"ignore\", \".*Missing logger folder.*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBGDvNGmvsCe"
      },
      "source": [
        "# Mon premier réseau de neurones artificiels\n",
        "\n",
        "Durant la deuxième partie de ce premier TP, vous allez travailler sur un autre jeu de données : [*forest cover types*](https://archive.ics.uci.edu/dataset/31/covertype).\n",
        "L'objectif est de prédire le type d'un arbre de forêt à partir de certaines caractéristiques.\n",
        "Il s'agit d'un problème de **classification**.\n",
        "\n",
        "En utilisant ce que vous avez appris dans le TP précédent, vous allez devoir :\n",
        "\n",
        "* **prétraiter les données**,\n",
        "* **indiquer comment accéder aux données**,\n",
        "* **construire un réseau de neurones**,\n",
        "* **entraîner et évaluer ce réseau de neurones**\n",
        "\n",
        "Nous utiliserons le paquet `scikit-learn` pour télécharger ce jeu de données. Comme d'habitude, on installe les paquets nécessaires qui ne sont pas déjà installés sur Colab :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsMbxZLpvsCf"
      },
      "source": [
        "Nous allons (télé)charger ce jeu de données en utilisant la fonction [`sklearn.datasets.fetch_covtype()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html).\n",
        "En résumé, cette fonction renvoie deux variables :\n",
        "\n",
        "* `X` est une matrice (un tableau NumPy à deux dimensions) de taille $n \\times p$ où $n$ est le nombre d'observations et $p$ est le nombre de variables. Ce sont les données en entrée.\n",
        "* `y` est un vecteur (un tableau NumPy à une dimension) de taille $n$. Ce sont les données en sortie (à prédire)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1qfDZ263vsCg"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "X, y = fetch_covtype(data_home='data', return_X_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur9naYz2vsCh"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "1. Déterminez la taille du jeu de données, c'est-à-dire le nombre d'observations $n$ et le nombre de variables $p$. Vous pouvez utiliser l'attribut [`numpy.ndarray.shape`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.shape.html)\n",
        "\n",
        "2. Déterminez le nombre de classes. Est-ce que les classes sont équilibrées ? Vous pouvez utiliser la fonction [`numpy.unique()`](https://numpy.org/doc/stable/reference/generated/numpy.unique.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "Bix9SwLovsCi",
        "outputId": "64c54867-9ce4-4022-a337-a65fa321f2e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(581012, 54) (581012,)\n",
            "Nombre de classes : 7\n",
            "Classes équilibrées : [211840 283301  35754   2747   9493  17367  20510]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 7 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO\n",
        "import numpy as np\n",
        "print(X.shape, y.shape)\n",
        "print(f\"Nombre de classes : {len(np.unique(y))}\")\n",
        "print(f\"Classes équilibrées : {np.unique(y, return_counts=True)[1]}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "plt.bar(np.unique(y), np.unique(y, return_counts=True)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notre jeu de données est composé de 581 012 observations composées de 54 variables plus la variable à prédire.\n",
        "On constate que les classes sont peu équilibrées car certains types d'arbres sont bcp + présents."
      ],
      "metadata": {
        "id": "6geZJC0H2Gcz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wn-zYMQvsCi"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Séparez le jeu de données en trois :\n",
        "* un jeu d'entraînement avec 100 000 observations,\n",
        "* un jeu de validation avec 100 000 observations,\n",
        "* un jeu d'évaluation (reste).\n",
        "\n",
        "Vous pouvez utiliser la fonction [`sklearn.model_selection.train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
        "Assurez-vous que la distribution des classes est identique dans les trois sous-jeux de données en utilisant le paramètre `stratify`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jIIuHzLmvsCj"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "y = y-1\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_remaining, y_train, y_remaining = train_test_split(X, y, train_size= 100000, stratify = y)\n",
        "x_test, x_eval, y_test, y_eval = train_test_split(x_remaining, y_remaining, train_size= 100000, stratify = y_remaining)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yne1i8vvsCj"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Convertissez les tableaux NumPy en tenseurs PyTorch. N'oubliez pas de changer le type des données :\n",
        "* les données en entrée (`X`) doivent passer de `numpy.float64` à `torch.float32`,\n",
        "* les données en sortie (`y`) doivent passer de `numpy.int32` à `torch.int64`.\n",
        "\n",
        "Vous pouvez utiliser la fonction [`torch.from_numpy()`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) et la méthode [`torch.Tensor.to()`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html).\n",
        "\n",
        "> **Remarque** : Pour les tâches de classification, il est nécessaire de fournir une représentation adaptée des classes pour la fonction de coût. La représentation la plus simple pour une tâche de classification multi-classes est d'utiliser les $K$ premiers entiers naturels (en commençant à partir de zéro), c'est-à-dire les entiers $0, \\ldots, K-1$, $K$ étant le nombre de classes. De cette manière, la correspondance entre la dernière couche du réseau de neurones (renvoyant les probabilités ou les logits) et les classes est basée sur les indicies : `probabilité[k]` correspond à la probabilité d'appartenir à la classe $k$ pour chaque $k \\in \\{ 0, \\ldots, K-1 \\}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FvkPd3rqvsCj"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "import torch\n",
        "x_train = torch.from_numpy(x_train).to(torch.float32)\n",
        "x_test = torch.from_numpy(x_test).to(torch.float32)\n",
        "x_eval = torch.from_numpy(x_eval).to(torch.float32)\n",
        "\n",
        "y_train = torch.from_numpy(y_train).to(torch.int64)\n",
        "y_test = torch.from_numpy(y_test).to(torch.int64)\n",
        "y_eval = torch.from_numpy(y_eval).to(torch.int64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbWeRonjvsCk"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "Créez des instances de la classe [`torch.utils.data.Dataloader()`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) pour chacun des jeux (entraînement, validation et évaluation). Pour les jeux de données, vous pouvez utiliser la classe [`torch.utils.data.TensorDataset()`](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bPOjmV0ovsCk"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "from torch.utils.data import TensorDataset\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "test_dataset = TensorDataset(x_test, y_test)\n",
        "eval_dataset = TensorDataset(x_eval, y_eval)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True, )\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size = 32, shuffle = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in train_dataloader:\n",
        "    print(y.min().item(), y.max().item())\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsAmtjkvCpvi",
        "outputId": "aeb479a3-f01f-4287-c0bd-502e71b11451"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx5SYdcYvsCk"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "La définition des caractéristiques principales du modèle (architecture) et de son entraînement (algorithme d'optimisation, fonction de perte, métrique d'évaluation) se fait dans une même classe.\n",
        "Complétez les méthodes `__init__()`, `forward()` et `configure_optimizers()` de la classe `NeuralNetwork` définie ci-dessous en utilisant les informations fournies dans le texte ci-dessous.\n",
        "\n",
        "#### Architecture\n",
        "\n",
        "L'architecture de votre réseau de neurones est un **perceptron multicouche** avec les caractéristiques suivantes :\n",
        "* *Première couche cachée* : couche linéaire (128 variables en sortie) + fonction d'activation ReLU\n",
        "* *Deuxième couche cachée* : couche linéaire (64 variables en sortie) + fonction d'activation ReLU\n",
        "* *Dernière couche cachée* : couche linéaire (à vous de déterminer la taille de la sortie)\n",
        "\n",
        "Pour rappel, les couches sont initialisées dans le constructeur et la définition de la passe avant se fait dans la méthode `forward()`.\n",
        "Vous êtes encouragés à aller lire la documentation de [`torch.nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html), [`torch.nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) et [`torch.nn.Sequential()`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html).\n",
        "\n",
        "#### Entraînement\n",
        "\n",
        "Le modèle sera entraîné en utilisant l'entropie croisée comme fonction de perte et Adam avec les valeurs par défaut pour ses hyperparamètres comme algorithme d'optimisation.\n",
        "Vous êtes encouragés à aller lire la documentation de [`torch.nn.CrossEntropyLoss()`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) et [`torch.optim.Adam()`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html).\n",
        "\n",
        "#### Métrique\n",
        "\n",
        "La performance d'un modèle sera évalué en utilisant l'exactitude (*accuracy*).\n",
        "Vous pouvez utiliser [`torchmetrics.Accuracy()`](https://lightning.ai/docs/torchmetrics/stable/classification/accuracy.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PXlwSCp5vsCl"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "\n",
        "class NeuralNetwork(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructeur.\n",
        "\n",
        "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
        "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
        "        \"\"\"\n",
        "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "        # Initialisation de la séquence de couches et de fonctions d'activation\n",
        "        self.sequential = torch.nn.Sequential(\n",
        "            torch.nn.Linear(1*54, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(64,7)\n",
        "        )\n",
        "        # Initialisation de la fonction de perte\n",
        "        self.loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        # Initialisation des métriques d'évaluation\n",
        "        self.accuracy_train = Accuracy(task=\"multiclass\", num_classes=7)\n",
        "        self.accuracy_val = Accuracy(task=\"multiclass\", num_classes=7)\n",
        "        self.accuracy_test = Accuracy(task=\"multiclass\", num_classes=7)\n",
        "        #### END TODO ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implémente la passe avant.\n",
        "\n",
        "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
        "        observation soit aux entrées d'un lot d'observations.\n",
        "        \"\"\"\n",
        "        ### BEGIN TODO ###\n",
        "        y = self.sequential(x)\n",
        "        #### END TODO ####\n",
        "        return y\n",
        "\n",
        "    def step(self, batch, dataset):\n",
        "        \"\"\"Effectue une étape.\n",
        "\n",
        "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
        "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch : tuple\n",
        "            Un lot d'observations. Le premier élément du tuple est le lot\n",
        "            des entrées, le second est le lot des labels.\n",
        "\n",
        "        dataset : {\"training\", \"validation\", \"test\"}\n",
        "            Jeu de données utilisé.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : Tensor, shape = (1,)\n",
        "            La fonction de coût pour ce lot d'observations.\n",
        "        \"\"\"\n",
        "        X, y = batch  # X correspond aux images, y aux classes\n",
        "        logits = self(X)  # Passe avant, qui renvoie les logits\n",
        "        loss = self.loss(logits, y)  # Évaluation de la fonction de perte\n",
        "        y_pred = logits.argmax(1)  # Prédictions du modèle\n",
        "\n",
        "        if dataset == \"training\":\n",
        "            metric = self.accuracy_train\n",
        "            name = \"train\"\n",
        "            bar_step = True\n",
        "        elif dataset == \"validation\":\n",
        "            metric = self.accuracy_val\n",
        "            name = \"val\"\n",
        "            bar_step = False\n",
        "        else:\n",
        "            metric = self.accuracy_test\n",
        "            name = \"test\"\n",
        "            bar_step = False\n",
        "\n",
        "        acc = metric(y_pred, y) # Évaluation de la métrique\n",
        "        self.log(f\"loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "        self.log(f\"accuracy_{name}\", acc, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
        "        return self.step(batch, \"training\")\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        \"\"\"Effectue une étape de validation.\"\"\"\n",
        "        return self.step(batch, \"validation\")\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
        "        return self.step(batch, \"test\")\n",
        "\n",
        "    def on_train_start(self):\n",
        "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
        "        string = f\"Version {self.trainer.logger.version}\"\n",
        "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
        "        metrics = self.trainer.callback_metrics\n",
        "        string = (f\"\"\"\n",
        "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
        "            -------------------------------------------------\n",
        "            |     Jeu      | Fonction de perte | Exactitude |\n",
        "            | ------------ | ----------------- | ---------- |\n",
        "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['accuracy_train'].item():^12.3%}|\n",
        "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['accuracy_val'].item():^12.3%}|\n",
        "            -------------------------------------------------\n",
        "        \"\"\")\n",
        "        string = '\\n'.join([line.strip() for line in string.strip().split('\\n')])\n",
        "        print(string, \"\\n\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
        "        ### BEGIN TODO ###\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        #### END TODO ####\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYgKSE88vsCm"
      },
      "source": [
        "On va maintenant entraîner le modèle pendant 10 époques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "CHXB5stevsCm",
        "outputId": "c2ebf393-822b-4312-8af3-efce6564c209"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    597\u001b[0m         )\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;31m# strategy will configure model and move it to the device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/strategy.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/accelerators/cuda.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_nvidia_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0m_clear_cuda_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/fabric/accelerators/cuda.py\u001b[0m in \u001b[0;36m_clear_cuda_memory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_clearCublasWorkspaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1980274722.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m trainer.fit(\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0m_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;31m# teardown might access the stage so we reset it after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\n\u001b[1;32m   1033\u001b[0m         those are handled by :meth:`_call_teardown_hook`.\"\"\"\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/strategy.py\u001b[0m in \u001b[0;36mteardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/accelerators/cuda.py\u001b[0m in \u001b[0;36mteardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0m_clear_cuda_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/fabric/accelerators/cuda.py\u001b[0m in \u001b[0;36m_clear_cuda_memory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# https://github.com/pytorch/pytorch/issues/95668\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_clearCublasWorkspaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "from lightning.pytorch.callbacks import TQDMProgressBar\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=10,\n",
        "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
        "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
        "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
        "    callbacks=[TQDMProgressBar(refresh_rate=100)]  # mettre à jour la barre de progression tous les 100 lots\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=model,\n",
        "    train_dataloaders=train_dataloader,\n",
        "    val_dataloaders=eval_dataloader\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRHrrKe0vsCm"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "Est-ce que l'exactitude (*accuracy*) est une métrique appropriée ici ?\n",
        "Quelle métrique serait davantage pertinente ?\n",
        "Y a-t-il également des modifications à faire pour potentiellement améliorer l'entraînement ?\n",
        "Regardez la documentation de [`torchmetrics.Accuracy()`](https://lightning.ai/docs/torchmetrics/stable/classification/accuracy.html) et de [`torch.nn.CrossEntropyLoss()`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) et faîtes les modifications nécessaires dans la méthode `forward()`.\n",
        "Vous pouvez utiliser la fonction [`torch.bincount()`](https://pytorch.org/docs/stable/generated/torch.bincount.html) pour compter le nombre d'observations pour les différentes classes.\n",
        "\n",
        "> **Remarque** : L'exactitude équilibrée (*balanced accuracy*) nécessite de connaître la distribution des classes pour connaître les poids des classes. La distribution des classes étant connue à la fin (quand on a parcouru tout le jeu de données), il n'est donc pas possible de calculer les scores d'exactitude équilibrée sur tous les lots intermédiaires. La bonne approche est de *mettre à jour* la métrique (avec la méthode `update()`) à chaque étape (*step*), puis de calculer l'exactitude équilibrée à la fin de l'époque (avec la méthode `compute()`) et enfin de réinitialiser les informations sauvegardées sous le capot pour calculer l'exactitude équilibrée (avec la méthode `reset()`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "D_bX4GG3vsCm"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "from torch import nn\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "\n",
        "class NeuralNetworkUpdated(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructeur.\n",
        "\n",
        "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
        "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
        "        \"\"\"\n",
        "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
        "\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(54, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 7),\n",
        "        )\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "        # self.loss =\n",
        "        # self.bal_acc_train =\n",
        "        # self.bal_acc_val =\n",
        "        # self.bal_acc_test =\n",
        "        #### END TODO ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implémente la passe avant.\n",
        "\n",
        "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
        "        observation soit aux entrées d'un lot d'observations.\n",
        "        \"\"\"\n",
        "        return self.sequential(x)\n",
        "\n",
        "    def step(self, batch, dataset):\n",
        "        \"\"\"Effectue une étape.\n",
        "\n",
        "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
        "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch : tuple\n",
        "            Un lot d'observations. Le premier élément du tuple est le lot\n",
        "            des entrées, le second est le lot des labels.\n",
        "\n",
        "        dataset : {\"training\", \"validation\", \"test\"}\n",
        "            Jeu de données utilisé.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : Tensor, shape = (1,)\n",
        "            La fonction de coût pour ce lot d'observations.\n",
        "        \"\"\"\n",
        "        X, y = batch  # X correspond aux images, y aux classes\n",
        "        logits = self(X)  # Passe avant, qui renvoie les logits\n",
        "        loss = self.loss(logits, y)  # Évaluation de la fonction de perte\n",
        "        y_pred = logits.argmax(1)  # Prédictions du modèle\n",
        "\n",
        "        if dataset == \"training\":\n",
        "            metric = self.bal_acc_train\n",
        "            name = \"train\"\n",
        "            bar_step = True\n",
        "        elif dataset == \"validation\":\n",
        "            metric = self.bal_acc_val\n",
        "            name = \"val\"\n",
        "            bar_step = False\n",
        "        else:\n",
        "            metric = self.bal_acc_test\n",
        "            name = \"test\"\n",
        "            bar_step = False\n",
        "\n",
        "        acc = metric(y_pred, y) # Évaluation de la métrique\n",
        "        self.log(f\"weighted_loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "        self.log(f\"balanced_accuracy_{name}\", acc, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
        "        return self.step(batch, \"training\")\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        \"\"\"Effectue une étape de validation.\"\"\"\n",
        "        return self.step(batch, \"validation\")\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
        "        return self.step(batch, \"test\")\n",
        "\n",
        "    def on_train_start(self):\n",
        "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
        "        string = f\"Version {self.trainer.logger.version}\"\n",
        "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
        "        self.log('balanced_accuracy_train', self.bal_acc_train.compute())\n",
        "        self.bal_acc_train.reset()\n",
        "\n",
        "        metrics = self.trainer.callback_metrics\n",
        "        weighted_loss_train = metrics['weighted_loss_train'].item()\n",
        "        weighted_loss_val = metrics['weighted_loss_val'].item()\n",
        "        bal_acc_train = metrics['balanced_accuracy_train'].item()\n",
        "        bal_acc_val = metrics['balanced_accuracy_val'].item()\n",
        "\n",
        "        string = (f\"\"\"\n",
        "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
        "            ------------------------------------------------------------\n",
        "            |     Jeu      | Fonction de perte | Exactitude équilibrée |\n",
        "            | ------------ | ----------------- | --------------------- |\n",
        "            | Entraînement |{weighted_loss_train:^19.5f}|{bal_acc_train:^23.3%}|\n",
        "            |  Validation  |{weighted_loss_val:^19.5f}|{bal_acc_val:^23.3%}|\n",
        "            ------------------------------------------------------------\n",
        "        \"\"\")\n",
        "        string = '\\n'.join([line.strip() for line in string.strip().split('\\n')])\n",
        "        print(string, \"\\n\")\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.log('bal_acc_val', self.bal_acc_val.compute())\n",
        "        self.bal_acc_val.reset()\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.log('bal_acc_test', self.bal_acc_test.compute())\n",
        "        self.bal_acc_test.reset()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym-cOgl2vsCn"
      },
      "source": [
        "On entraîne un nouveau modèle pendant $10$ époques également."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "c83Tun6BvsCn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ef245f0a-9b73-4851-9b02-0478b6eaedbf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataloader_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3293457145.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m trainer.fit(\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_updated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataloader_train' is not defined"
          ]
        }
      ],
      "source": [
        "model_updated = NeuralNetworkUpdated()\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=10,\n",
        "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
        "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
        "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
        "    callbacks=[TQDMProgressBar(refresh_rate=100)]  # mettre à jour la barre de progression tous les 100 lots\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=model_updated,\n",
        "    train_dataloaders=dataloader_train,\n",
        "    val_dataloaders=eval_dataloader\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx9dQq4-vsCo"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "Faîtes les modifications que vous souhaitez, par exemple au niveau de l'architecture ou de la procédure d'entraînement, et entraînez vos nouveaux modèles.\n",
        "**Gardez vos modèles précédents** et créez de nouveaux objets à chaque fois, afin de pouvoir comparer ces différents modèles ensuite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3zeRsBdvsCo"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d23FXb9vsCo"
      },
      "source": [
        "### Question 8\n",
        "\n",
        "Quand vous avez fini toutes vos expériences, il est temps de choisir le meilleur modèle sur le jeu de validation.\n",
        "Évaluez sa performance sur le jeu d'évaluation.\n",
        "Par curiosité, évaluez également la performance des autres modèles sur le jeu d'évaluation.\n",
        "Vous êtes encouragés à aller lire la [documentation](https://lightning.ai/docs/torchmetrics/stable/pages/overview.html) de `torchmetrics` pour découvrir le principe d'utilisation des métriques implémentées dans ce paquet.\n",
        "\n",
        "> **Remarque** : La première classe utilise l'exactitude (*accuracy*) comme métrique d'évaluation, tandis que la deuxième classe utilise l'exactitude équilibrée (*balanced accuracy*). Il n'est évidemment pas pertinent de comparer des scores d'exactitude avec des scores d'exactitude équilibrée. De même, la fonction de perte est maintenant pondérée dans la deuxième classe. Il n'est donc pas possible d'utiliser les méthodes `validate()` et `test()` pour comparer des modèles définis par des classes différentes si les classes utilisent différents critères d'évaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Szi2sAeEvsCo"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}